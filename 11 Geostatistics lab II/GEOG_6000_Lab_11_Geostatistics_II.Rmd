---
title: "GEOG 6000 Lab 12 Geostatistics II"
author: "Simon Brewer"
date: "10/14/2020"
output:
  html_document:
    toc: true
    toc_float: true
    fig_caption: true
    css: "../style.css"
---

```{r echo=FALSE}
options(width=50)
set.seed(1234)
```

In this lab, we will continue the steps of a geostatistical analysis, using the set of precipitation data for Switzerland, and the data set of soil samples from a floodplain near the Meuse river in the Netherlands. 

Before starting the lab, you will need to set up a new folder for your working directory. Go to your `geog6000` folder now and create a new folder for today's class called `lab11`. The following files will be used in this lab, all available on Canvas:  

- *swiss_ppt.zip*. This contains a set of point observations of rainfall in Switzerland
- *meuse.zip*. This contains the shapefiles for the Meuse soil sample data set as well as the river borders 
- *ne_50m_admin_0_countries.zip*. This contains a shapefile of country outlines
- *oregon.zip*: Oregon temperature dataset 

You should have these files from last week's lab, but if not you will need to download these files from Canvas, and move them from your `Downloads` folder to the `datafiles` folder that you made previously. Make sure to unzip the zip files so that R can access the content. Note that on Windows, you will need to right-click on the file and select 'Extract files'. 

Now start RStudio and change the working directory to `lab11`. As a reminder, you can do this by going to the [Session] menu in RStudio, then [Change working directory]. This will open a file browser that you can use to browse through your computer and find the folder. 

You will also need three packages to carry out all the steps listed here: **sf**, **stars** and **gstat**. Again, you should these installed from last weeks lab, but if not make sure these are installed these before starting. 

```{r, eval = FALSE}

pkgs <- c("gstat",
          "stars",
          "sf")

install.packages(pkgs)

```

**With all the examples given, it is important to not just type in the code, but to try changing the parameters and re-running the functions multiple times to get an idea of their effect.** Help on the parameters can be obtained by typing `help(functionname)` or `?functionname`. 

# Setting projections for **gstat**

By default **gstat** assumes that your data are in a Cartesian projection, unless the Spatial* object containing the data has projection metadata specifying that it is on a spherical (lat/lon) coordinate system. Without this, longitude and latitude coordinates will be treated as Cartesian, and distances will be incorrectly calculated for variogram analysis and kriging. We can illustrate this with the Oregon dataset. Load this and check the associated projection (this should read 'NA'):

```{r}
library(sf)
library(stars)
oregon = st_read("../datafiles/oregon/oregontann.shp")
st_crs(oregon)
```

Now make a variogram for the temperature variable (first load the **gstat** package):

```{r message=FALSE, fig.keep='none'}
library(gstat)
plot(variogram(tann ~ 1, oregon))
```

The distance lags are calculated in degrees. To correct this, we can either project the data or simply specify that these data are spherical coordinates. In general, the second of these is a better approach, unless you are working in a very small area, as all projections will distort distances and/or directions over large areas. Here, we set the `st_crs` to [EPSG 4326][epsgID], which is the WGS84 standard:

```{r}
st_crs(oregon) <- 4326
```

Now if we remake the variogram, **gstat** recognizes this as spherical coordinates, and calculates distances as great circle distances in km, rather than Euclidean degrees, reducing the bias in distances.

```{r message=FALSE, fig.keep='none'}
plot(variogram(tann ~ 1, oregon))
```

# Reading the data

This code is taken from last week's lab and will load and convert all the necessary files for the Swiss precipitation data:

```{r message=FALSE, results='hide'}
## Precipitation data
swiss <- read.csv("../datafiles/swiss_ppt/swiss_ppt.csv")
swiss.sf <- st_as_sf(swiss, 
                     coords = c("x", "y"),
                     crs = 2056)
## Elevation grid
swiss.dem <- read_stars("../datafiles/swiss_ppt//swiss_dem.asc")
st_crs(swiss.dem) <- 2056
## Swiss border
countries <- st_read("../datafiles/ne_50m_admin_0_countries/ne_50m_admin_0_countries.shp")
swiss.bord <- subset(countries, NAME == "Switzerland")
swiss.bord <- st_transform(swiss.bord, 2056)
```

Make a simple plot of precipitation amounts:

```{r}
plot(swiss.sf["ppt"], reset = FALSE, pch = 16)
plot(st_geometry(swiss.bord), add = TRUE)
```


```{r fig.keep='high', message=FALSE}
library(ggplot2)
ggplot() + 
  geom_sf(data = swiss.bord) +
  geom_sf(data = swiss.sf, aes(col = ppt), size = 2.5) +
  theme_bw()
```

Now load the Meuse datasets:

```{r results='hide'}
meuse <- st_read("../datafiles/meuse/meuse.shp")
st_crs(meuse) <- 28992

meuse.riv <- st_read("../datafiles/meuse/meuseriv.shp")
st_crs(meuse.riv) <- 28992

meuse.grid <- st_read("../datafiles/meuse/meusegrid.shp")
st_crs(meuse.grid) <- 28992
meuse.grid <- st_rasterize(meuse.grid["dist"], dx = 40, dy = 40)

```

# Kriging with external drift

Kriging can be extended to include covariates to improve prediction. One of the most flexible methods is kriging with an external drift, where the drift refers to any covariate that has been recorded both at the sampling locations and at the prediction locations. A scatterplot of the precipitation against the elevation of each site shows a weak negative relationship, with generally higher values at lower elevations:
```{r fig.keep='none'}
plot(ppt ~ elev, swiss.sf)
```

We will use this model together with elevation data from the DEM to perform kriging with an external drift on the precipitation data. As we are incorporating a covariate in our model, we first need to remake the precipitation variogram, so that the variogram takes this into account: 

```{r}
ppt.var <- variogram(ppt ~ elev, swiss.sf)
plot(ppt.var, plot.numbers=TRUE)
```

Now let's fit a model as we did before:

```{r}
modNugget <- 10
modRange <- 75000
modSill <- 140
ppt.vgm1 <- vgm(psill=modSill, "Sph", range=modRange, nugget=modNugget)
ppt.vgm2 <- fit.variogram(ppt.var, ppt.vgm1)
plot(ppt.var, ppt.vgm2, main="Swiss precip. variogram")
```

We will now use this variogram to interpolate the precipitation data. We use the same function as in the previous lab (`krige()`), but now specify 'elev' as an independent variable in the model formula. This requires that both the spatial points (`swiss.sf`) and the new locations (`swiss.dem`) have a variable called `elev', so let's check this first:

```{r results='hide'}
## Check to see that both the data and grid have elev variables
names(swiss.sf)
names(swiss.dem)
```
This shows that the `swiss.dem` variable was named using the original file name. let's rename this

```{r}
names(swiss.dem) <- "elev"
```

Now we can go ahead and run the model:

```{r}
## kriging with external drift
ppt.pred.ked <- krige(ppt ~ elev, swiss.sf, swiss.dem, ppt.vgm2)
```

Plot the new predictions:
```{r fig.keep='none'}
ppt.pred.ked
library(RColorBrewer)
my.pal = brewer.pal(9, "Blues")
plot(ppt.pred.ked["var1.pred"], col = my.pal, 
     main = "Swiss precipitation (KED)")
```

As before, we can estimate the prediction skill of the model using cross-validation:
```{r results='hide'}
ppt.cv.ked <- krige.cv(ppt ~ elev, swiss.sf, ppt.vgm2, nmax=40, nfold=5)
sqrt(mean(ppt.cv.ked$residual^2))
cor(ppt.cv.ked$observed, ppt.cv.ked$var1.pred)^2
```

# Regression kriging

Regression kriging provides a more flexible approach to including covariates than universal kriging or external drift kriging, but requires a little more work. The idea is that rather than trying to incorporate a potentially complicated relationship in the model, this is modeled separately, then the residuals are interpolated using simple kriging. A final estimate at each new location can then be made by adding the predicted value from the original model to the interpolated residual. This opens up the possibility of using any regression technique with the covariate(s) to model the larger, structural trends, and then using simple kriging to model the deviations from this trend. 

As a simple example, we will build a linear model of precipitation using elevation as the covariate, and use the residuals from this as the basis for kriging. Note that as we have specified the covariate in the regression model, we no longer need to include it in the variogram or the `krige()` function. 

```{r fig.keep='none'}
fit1 = lm(ppt ~ elev, swiss.sf)
swiss.sf$resid = residuals(fit1)
resid.var = variogram(resid ~ 1, swiss.sf)
plot(resid.var)
```

Now fit a variogram model to this:
```{r fig.keep='none'}
resid.vgm = vgm(145, "Cir", 75000, 5)
plot(resid.var, resid.vgm)
```

We now interpolate the residuals (I haven't fit the variogram model to the sample data, but feel free to do so). Note that as these are residuals, the mean is assumed known ($=0$), so we use simple kriging for the interpolation. The parameter `beta` is used to set the value of the mean:

```{r fig.keep='none'}
resid.sk = krige(resid ~ 1, swiss.sf, swiss.dem, resid.vgm, nmax=40, beta=0)
my.pal <- brewer.pal(9, "PRGn")
plot(resid.sk["var1.pred"], col = my.pal, 
     main = "Swiss precipitation residuals (RK)")

```

To make the final estimates, we first predict the precipitation using the simple linear model and the elevation values on the DEM, and store this in the `stars` DEM object:

```{r}
swiss.dem$ppt.lm = predict(fit1, swiss.dem)
```

Now we add the interpolated residuals to these values:
```{r fig.keep='high'}
swiss.dem$ppt.rk = swiss.dem$ppt.lm + resid.sk$var1.pred
```

And finally visualize the predictions:
```{r fig.keep='high'}
my.pal <- brewer.pal(9, "Blues")
plot(swiss.dem["ppt.rk"], col = my.pal, 
     main = "Swiss precipitation (Regression Kriging)")

```

Note that there are various issues with this model, not least of which are the presence of negative precipitation values at higher elevations. This is partly limited by the poor relationship between elevation and precipitation in this data, and by the fact that a linear model may not be the best choice. A log-transformation of precipitation may help with the link between elevation and we could replace the linear model with a more flexible approach (e.g. generalized additive models or machine learning methods). 

# Indicator Kriging

Indicator kriging is used to interpolate binary variables as probabilities. It can be used to estimate whether the variable of interest will be over or below a given threshold at a new location, or the probability that a new location will have a binary or categorical variable. In either case, the method consists quite simply of interpolating binary values (0/1) using ordinary kriging. As this uses the same function as before, you can include a trend or external drift if necessary. 

## Thresholds

We'll first use this method to find all locations in Switzerland with over 40mm of rainfall. Here, we create a new variable in the `swiss.sf` data frame, which is whether or not the station had $>$ 40mm rainfall, and use `spplot()` to make a quick figure. 

```{r fig.keep='none'}
swiss.sf$ppt40 = swiss.sf$ppt > 40
plot(swiss.sf["ppt40"], pch = 16, 
       main="PPT > 40mm")
```

Now we proceed as in the previous lab: 

1. Create the sample variogram
```{r fig.keep='none'}
ppt40.var <- variogram(ppt40 ~ 1, swiss.sf)
plot(ppt40.var)
ppt40.vgm = vgm(0.035, "Sph", 40000, 0.01)
plot(ppt40.var, ppt40.vgm)
```
2. Fit a variogram model
```{r fig.keep='none'}
ppt40.vgm2 = fit.variogram(ppt40.var, ppt40.vgm)
plot(ppt40.var, ppt40.vgm2)
```
3. Interpolate using ordinary kriging:
```{r fig.keep='none', message=FALSE, results='hide'}
ppt40.ik <- krige(ppt40 ~ 1, swiss.sf, swiss.dem, ppt40.vgm2, nmax=40)
```
4. Plot the new predictions:
```{r fig.keep='none'}
plot(ppt40.ik)
```

Note that these are not true probabilities (some values $<0$ are obtained). For the purposes of geostatistical interpolation, however, these are considered as close to being probabilities and are often corrected to between 0 and 1. Indicator simulation (see below) offers a method to interpolate true probabilities.

## Categorical variables
The Meuse data set contains soil type for each of the sampling sites, split into three classes. Use the `spplot()` function to look at their spatial distribution:
```{r fig.keep='none'}
plot(meuse["soil"], pch = 16, reset = FALSE)
plot(meuse.riv, add = TRUE, col = NA)
```

The individual categories can be interpolated to new locations using indicator kriging. As before we start by making and modeling the variogram, then interpolate onto a grid. 

Star by making and modeling the sample variogram. Note that rather than creating a new variable, we use the `I()` function, which tells R to create a new variable internally in a model, here a binary value where soil class 1 equals 1, and other classes equal zero:

```{r fig.keep='none'}
s1.var <- variogram(I(soil==1)~1, meuse, cutoff=2000)
s1.vgm <- vgm(psill=0.25, model="Sph", range=900, nugget=0.1)
s1.vgm <- fit.variogram(s1.var, s1.vgm)
plot(s1.var, s1.vgm, main="Soil class 1")
```

We now interpolate using the `krige()` function:
```{r fig.keep='none', results='hide'}
s1.ik <- krige(I(soil==1)~1, meuse, meuse.grid, s1.vgm)
plot(s1.ik)
```

Now do the same for the other two soil classes, to get interpolated probabilities for class 2 (`s2.ik`) and 3 (`s3.ik`).

```{r include=FALSE}
s2.var <- variogram(I(soil==2)~1, meuse, cutoff=2000)
s2.vgm <- fit.variogram(s2.var, 
                        model=vgm(psill=0.25, model="Sph", range=900, nugget=0.1))
plot(s2.var, s2.vgm, main="Soil class 2")
s2.ik <- krige(I(soil==2)~1, meuse, meuse.grid, s2.vgm)

s3.var <- variogram(I(soil==3)~1, meuse, cutoff=2000)
s3.vgm <- fit.variogram(s3.var, 
                        model=vgm(psill=0.25, model="Sph", range=900, nugget=0.1))
plot(s3.var, s3.vgm, main="Soil class 3")
s3.ik <- krige(I(soil==3)~1, meuse, meuse.grid, s3.vgm)
```

Once you have the probabilities for all three classes, we can use these to estimate the most probable class at each new location. We do this in three steps: first, combine the individual probability interpolations into a single matrix; second, find for each row, the column with the highest probability using `max.col()` and assign the output as a new variable in `meuse.grid`; third, plot the results.

```{r fig.keep='none'}
soil.prob = cbind(c(s1.ik$var1.pred), c(s2.ik$var1.pred), c(s3.ik$var1.pred))
meuse.grid$soil.pred <- max.col(soil.prob)
plot(meuse.grid["soil.pred"])
```

This can be extended to larger numbers of classes, as long as there is sufficient data to produce a variogram for each one, and that you have the patience to model them all. 

# Geostatistical simulation

All geostatistical simulation methods are designed to produce random spatial fields, where the value at each location is produced by random draws from a probability distribution function defined by the observations. In contrast to straightforward generation of random values, spatially random fields produce random values at each location, but while preserving spatial structure. Individual simulations are much less smooth than kriging interpolation, as the values at any two neighboring locations are randomly chosen, but are spatially correlated as described by a variogram. 

Geostatistical simulations come in two forms: constrained and unconstrained. In the unconstrained type, the random field is based on a specified mean and variance, and the variogram for spatial structure. The random fields produced have the same statistical and spatial characteristics, but the minima and maxima may occur anywhere in the study area. Constrained simulations also include the location and value of the observed points. This ensures that minima and maxima occur where they are defined by the original points, and the resulting fields have the same pattern as the original data. We will concentrate here on the constrained type of simulation. 

## Gaussian simulation
Like ordinary kriging, Gaussian simulation can be performed with continuous variables, and uses a similar setup to the kriging carried out above and in previous labs. We'll use this with the Swiss precipitation data, so first make a variogram and fit a variogram model. 

```{r include=TRUE}
modNugget <- 10
modRange <- 75000
modSill <- 140
ppt.var <- variogram(ppt ~ 1, swiss.sf)
ppt.vgm1 <- vgm(psill=modSill, "Sph", range=modRange, nugget=modNugget)
ppt.vgm2 <- fit.variogram(ppt.var, ppt.vgm1)
plot(ppt.var, ppt.vgm2, main="Swiss precip. variogram")
```

To carry out 6 random simulations of the Swiss precipitation data, we use the `krige()` function again, with the spatial data, output grid, variogram, etc. The new parameter used here is `nsim` which controls the number of output simulations:
```{r eval=TRUE}
ppt.pred.sgs <- krige(ppt ~ 1, swiss.sf, swiss.dem, 
                      ppt.vgm2, nmax=40, nsim=6)
```

The `spplot()` function is very useful for visualizing the output as it plots a grid of all required simulations:
```{r eval=TRUE}
my.pal <- brewer.pal(9, "Blues")
plot(ppt.pred.sgs, col = my.pal, 
     main = "Swiss ppt (SGS)")
```

In general, single simulations are only of interest to examine the degree of variation between observations (as opposed to kriging which provides smoothed interpolations). The power of the simulation approach is in producing a large number of possible realizations of a spatial field. This allows a better assessment of uncertainty at any location, as we can obtain not just the mean estimated value and a confidence interval, but the full probability distribution of interpolated values. 

In the next bit of code, we will produce one hundred simulations of precipitation, then extract the predicted values for a single point and make this into a histogram. So first, re-run the `krige` function with a higher number of simulations:

```{r eval=TRUE}
ppt.pred.sgs <- krige(ppt ~ 1, swiss.sf, swiss.dem, 
                      ppt.vgm2, nmax=40, nsim=100)
```

Next, we create a new point location to extract the simulated values. 

```{r eval=TRUE}
newloc <- st_geometry(st_point(c(2650000, 1200000)))
st_crs(newloc) <- st_crs(swiss.dem)
plot(swiss.dem, reset = FALSE, axes = TRUE)
plot(newloc, pch = "x", cex = 3, col = 2, add = TRUE)
```

We use the function `st_extract()` for extracting points, and then plot the resulting values as a histogram:

```{r eval=FALSE}
newloc.ppt = st_extract(ppt.pred.sgs, newloc)
hist(newloc.ppt$var1, breaks=20, col="darkorange", 
     main="Precipitation at (0,0)", xlab="mm")
```

Note that as we are using the same formula notation as kriging, we could easily extend the basic simulation approach to include covariates to represent external drifts or trends. 

## Indicator simulation

The simulation approach can also be used for indicator interpolation. As in the previous example, we simply reuse the `krige()` function. In addition to the `nsim` parameter, we include a parameter `indicators=TRUE` to perform indicator kriging. In this case, rather than each simulation estimating a probability at each new location, the method estimates a binary value (presence or absence) by drawing from a binomial distribution. 
To simulate 6 realizations of the distribution of soil class 1:

```{r eval=TRUE}
s1.sis <- krige(I(soil==1)~1, meuse, meuse.grid, s1.vgm, 
                nsim=6, indicators=TRUE, nmax=40)
plot(s1.sis)
```

If we now run multiple simulations, we can assess uncertainty. In this case, we get 1000 simulations of the presence of soil type 1 at each location. To estimate probability, we then take the sum of all presences (1) and divide by the number of simulations (1000). This is stored in the output, and then can be plotted using `spplot()`. 

```{r eval=FALSE}
s1.sim = krige(I(soil==1)~1, meuse, meuse.grid, s1.vgm,
               nsim=1000, indicators=TRUE, nmax=40)

s1.prob <- st_apply(s1.sim, c(1,2), sum) / 1000
plot(s1.prob)
```

In contrast to the indicator kriging, the output from this function provides true probabilities of presence, constrained to the range [0,1].

# Exercise

1. The compressed file *mwozone.zip* contains measurements of ground ozone concentration in the midwestern US for June 20, 1987 in the shapefile *ozone.shp*. The goal of this exercise is use this data to produce a map showing the probability that a certain threshold (100 ppb) was passed on that date. You can do this using either indicator kriging or indicator simulation, using the examples provided in the lab. You are free to approach this in your own way, but you will need to provide at least the following:

- A map of ozone concentrations at the measurement stations
- A plot of the sample variogram describing the spatial structure of the condition you want to interpolate (ozone $>$ 100 ppb), and a brief description of the spatial structure you observe
- A variogram model fitted to this (as a figure), and give the model chosen, the sill, range and nugget value (if appropriate)
- A map of predicted probabilities of passing 100 ppb ozone. In order to do this, you will need to create a longitude/latitude grid for interpolation. See code below for how to do this simply in R
- A brief description of the spatial pattern shown on the interpolated map --- what do you think the higher probabilities relate to?
    
## Code to add shapefiles

It may help to add other shapefiles to your maps for this exercise. The following code assumes that you have read in the ozone shapefile to a Spatial* object called `ozone.sp`, and adds state outlines, lakes and cities using the [Natural Earth datasets][neID]. The example here plots out the ozone concentrations, but you can adapt this pretty easily for the predicted values you obtain. Note that to run this code, you will need to make sure the **maptools** package is installed and download and unzip the following files from Canvas:

- *ne_50m_admin_1_states_provinces.zip*
- *ne_50m_lakes.zip*
- *ne_50m_populated_places.zip*

To overlay multiple shapefiles, we make a set of list objects, one per overlay, then include all of these in a list that is passed to the `sp.layout` argument. The purpose of making the individual lists is to allow you to specify parameters for each layer (e.g. fill colors):

```{r eval=FALSE, echo=FALSE}
ozone.sp = readOGR("mwozone/ozone.shp")
head(ozone.sp)
```
```{r eval=FALSE}
library(maptools)
## Read data
states = readOGR("ne_50m_admin_1_states_provinces/ne_50m_admin_1_states_provinces_shp.shp")
lakes = readOGR("ne_50m_lakes/ne_50m_lakes.shp")
places = readOGR("ne_50m_populated_places/ne_50m_populated_places.shp")
## Make overlay lists
statesl = list(states)
lakesl = list(lakes, fill = "lightblue")
placesl1 = list('sp.points', places, pch='+', cex=1.2, col='midnightblue')
placesl2 = list('sp.pointLabel', places, label=places$NAME,
            cex=0.7, col='midnightblue',
            fontfamily='Palatino')
## Pass all of this to spplot
spplot(ozone.sp, "ozone", sp.layout = list(statesl, lakesl, 
                                           placesl1, placesl2))
```
## Code to make a prediction grid
```{r eval=FALSE}
llCRS <- CRS("+proj=longlat +ellps=WGS84")
predgrid <- expand.grid(x=seq(-94, -82, 0.25), y=seq(36, 45, 0.25))
predgrid.sp = SpatialPixels(SpatialPoints(predgrid))
proj4string(predgrid.sp) <- llCRS
```

# File details
## Oregon annual temperature: *ortann.shp*

\begin{tabularx}{\linewidth}{| l | X |}
    \hline
  	Column header & Variable \\ 
		\hline
		elevation & Elevation a.s.l. (m) \\ 
		tann & Annual temperature (celsius) \\ 
		coords\_x1 & Longitude \\
    coords\_x2 & Latitude \\ 
		\hline
\end{tabularx}

## Meuse soil samples: *meuse.shp*
\begin{tabularx}{\linewidth}{| l | X |}
    \hline
  	Column header & Variable \\ 
		\hline
		cadmium & Cadmium concentration (ppm) \\
		copper & Copper concentration (ppm) \\
    lead & Lead concentration (ppm) \\ 
		zinc & Zinc concentration (ppm) \\ 
		elev & Elevation a.s.l. (m) \\ 
		dist & Distance to river (GIS) \\ 
		om & Organic matter (kg 100 kg$^{-1}$) \\ 
		ffreq & Flood frequency (class) \\ 
		soil & Soil type \\ 
		lime & Presence of lime \\ 
		landuse & Landuse class \\ 
		dist\_m & Distance to river (field) \\ 
		\hline
\end{tabularx}

## Midwest ozone values: *ozone.shp*

\begin{tabularx}{\linewidth}{| l | X |}
     \hline
  	Column header & Variable \\ 
		\hline
		lon & Longitude \\ 
		lat & Latitude \\ 
  	ozone & Ozone concentration (ppb) \\ 
		ozone100 & Ozone conc. over 100 ppb (True/False) \\ 
		coords\_x1 & Longitude \\
    coords\_x2 & Latitude \\ 
		\hline
\end{tabularx}


# R code covered in lab
\begin{tabularx}{\linewidth}{| l | X |}

\hline
R Command & Purpose \\
\hline
\multicolumn{2}{|l|}{\textbf{Variogram analysis}} \\
\hline
\texttt{variogram} & Build sample variogram using a SpatialPointsDataFrame or data frame. Parameters: \texttt{cutoff} define limit of variogram analysis; \texttt{width} defines the lag width. Anisotropy can be included with \texttt{anis}\\
\texttt{vgm} & Construct a variogram model. Parameters are entered in the following order: (partial sill), model type, range, nugget\\
\texttt{fit.variogram} & Fit a model built with \texttt{vgm} to a sample variogram using weighted OLS\\
\hline
\multicolumn{2}{|l|}{\textbf{Spatial prediction}} \\
\hline
\texttt{krige} & Carries out spatial prediction using kriging. Variable to be predicted is specified using R's model formula, and covariates can be introduced on the righthand side. \\
 & --- If no variogram model is include will perform inverse distance weighting \\
 & --- If variogram model is include will perform ordinary kriging \\
 & --- If parameter \texttt{nsim} is set will perform Gaussian simulation \\
 & --- If parameter \texttt{nsim} and parameter \texttt{indicators} are set will perform indicator simulation \\
\texttt{krige.cv} & Carries out $n$-fold cross validation using kriging\\
\hline
\end{tabularx}

[neID]: https://www.naturalearthdata.com
[epsgID]: https://spatialreference.org/ref/epsg/wgs-84/